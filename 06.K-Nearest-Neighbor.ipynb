{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-최근접 이웃 (K-Nearest Neighbor)\n",
    "- k 최근접 이웃 (K-Nearest-Neighbor, KNN)은 이름에서 알수 있듯, 비교 대상이 되는 데이터 포인트 주변에 가장 가까이 존재하는 k개의 데이터와 비교해 가장 가까운 데이터 종류로 판별한다.\n",
    "- 예를 들어, 과일 데이터를 구분할 때, 데이터 포인트 주변의 3개의 값을 비교한다고 가정하면, 데이터 주변의 반경 (circle)으로 표시하고 원 내부의 데이터와 비교해 분류하는 것이다. 데이터 주변의 가장 가까운 데이터를 판별하게 되며, 가장 많이 존재하는 것을분류하는 것이다. \n",
    "- k 최근접 이웃은 k의 값에 다라서 분류가 달라진다 \n",
    "- 만일, 타깃이 연속형 숫자라면 kNN은 k개의 데이터의 평균 값으로 에측하는 방법을 사용한다. 에를 들어 타깃 변수가 과일 당도이고, 주변의 3개의 데이터 값이 8,10,12 라면 KNN을 이용한 에측값으 3개의 데이터 평균값이 10이다. \n",
    "- k 최근접 이웃 알고리즘은 학습과정에서 게으른 학습(lazy learning)방법을 사용한다. 게으른 학습은 트레이닝 데이터 전체를 메모리상에 보관하면서 테스트 데이터가 새로 들어왔을 대 바로 학습하는 것을 의미한다. 게으른 학습은 트레이닝 데이터 전체를 메모리에 보관하므로 추가적인 학습 시간이 없이, 곧바로 학습 결과를 얻을 수 있다는 장점을 가지고 있다. 그러나 예측시 메모리상에 학습용 데이터를 항상 보관하고 있어야 하므로 메모리 용랴보다 데이터가 지나치게 커서 메모리에 보관할 수 없을 경우에는 사용할 수 없다는 단점을 가지고 있다 \n",
    "- 게으른 학습의 반대말은 열정적 학습이다 (eager learning). 이는 우리가 흔히 알고 있는 학습과정으로, 트레이닝 데이터로 일정 기간 학습시킨후 학습시킨 모형을 기반으로 데스트 데이터를 적용하는 방법이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "from sklearn import datasets\n",
    "raw_iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피쳐/타겟\n",
    "X = raw_iris.data\n",
    "y = raw_iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레이닝/테스트 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tn, X_te, y_tn, y_te=train_test_split(X,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 표준화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(X_tn)\n",
    "X_tn_std = std_scale.transform(X_tn)\n",
    "X_te_std  = std_scale.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 학습\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_knn =  KNeighborsClassifier(n_neighbors=2)\n",
    "clf_knn.fit(X_tn_std, y_tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNeighborsClassifier 함수를 이용해 사용할 모형을 지정, 가장 근접한 데이터 2개(n_neighbors=2)를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 1 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 예측\n",
    "knn_pred = clf_knn.predict(X_te_std)\n",
    "print(knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# 정확도 평가\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_te, knn_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  1  8]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix 확인 \n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_te, knn_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.94      0.94      0.94        16\n",
      "           2       0.89      0.89      0.89         9\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.94      0.94      0.94        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 분류 레포트 확인\n",
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(y_te, knn_pred)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
